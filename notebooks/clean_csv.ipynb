{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73704990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T06:24:20.902641Z",
     "start_time": "2026-01-03T06:24:20.829186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total songs loaded: 614\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"output/songs_with_lyrics.csv\")\n",
    "print(f\"Total songs loaded: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80f724ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T06:24:26.395237Z",
     "start_time": "2026-01-03T06:24:20.974187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting languages...\n",
      "\n",
      "Statistics:\n",
      "        line_count     char_count  symbol_count\n",
      "count   614.000000     614.000000    614.000000\n",
      "mean    311.801303    8010.833876    159.255700\n",
      "std     468.019331   21889.443694    326.262379\n",
      "min       0.000000       0.000000      0.000000\n",
      "25%      50.000000    1495.250000      2.250000\n",
      "50%      86.500000    2709.500000     16.000000\n",
      "75%     448.000000    7779.000000    259.500000\n",
      "max    3853.000000  413767.000000   4592.000000\n",
      "\n",
      "Tracklists detected: 44\n",
      "Annotated URLs detected: 301\n",
      "Non-English songs detected: 39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Count Lines\n",
    "def count_lines(text):\n",
    "    if pd.isna(text): return 0\n",
    "    return len(str(text).split('\\n'))\n",
    "\n",
    "df['line_count'] = df['lyrics'].apply(count_lines)\n",
    "\n",
    "# 2. Count Characters\n",
    "df['char_count'] = df['lyrics'].apply(lambda x: len(str(x)) if pd.notna(x) else 0)\n",
    "\n",
    "# 3. Detect Tracklists\n",
    "def is_tracklist(text):\n",
    "    if pd.isna(text): return False\n",
    "    matches = re.findall(r'^\\d+\\.', str(text), re.MULTILINE)\n",
    "    return len(matches) > 3\n",
    "\n",
    "df['is_tracklist'] = df['lyrics'].apply(is_tracklist)\n",
    "\n",
    "# 4. Count Symbols\n",
    "def count_symbols(text):\n",
    "    if pd.isna(text): return 0\n",
    "    return str(text).count('-') + str(text).count('>') + str(text).count(':')\n",
    "\n",
    "df['symbol_count'] = df['lyrics'].apply(count_symbols)\n",
    "\n",
    "# 5. Detect Annotated URLs\n",
    "def is_annotated(url):\n",
    "    return str(url).endswith('annotated')\n",
    "\n",
    "df['is_annotated'] = df['url'].apply(is_annotated)\n",
    "\n",
    "# 6. Detect Language\n",
    "def detect_language(text):\n",
    "    if pd.isna(text) or len(str(text).strip()) < 10: return 'unknown'\n",
    "    try: return detect(str(text))\n",
    "    except LangDetectException: return 'error'\n",
    "\n",
    "print(\"Detecting languages...\")\n",
    "df['language'] = df['lyrics'].apply(detect_language)\n",
    "\n",
    "# Show statistics\n",
    "print(\"\\nStatistics:\")\n",
    "print(df[['line_count', 'char_count', 'symbol_count']].describe())\n",
    "print(f\"\\nTracklists detected: {df['is_tracklist'].sum()}\")\n",
    "print(f\"Annotated URLs detected: {df['is_annotated'].sum()}\")\n",
    "print(f\"Non-English songs detected: {len(df[df['language'] != 'en'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac3e3cf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T06:24:26.402944Z",
     "start_time": "2026-01-03T06:24:26.399625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying 'Read More' preprocessing...\n",
      "Preprocessing complete.\n",
      "Sample processed lyric start:\n",
      "[Intro]\n",
      "Last night, I cried\n",
      "[Verse]\n",
      "Give me a second, give me a minute\n",
      "Nah, lil' bitch, can't let yo...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove \"Read More\" header and everything before it\n",
    "def lyrics_process(lyrics):\n",
    "    if pd.isna(lyrics): return \"\"\n",
    "    lyrics = str(lyrics)\n",
    "    # Check for \"Read More\" (case-sensitive based on your example)\n",
    "    # If found, keep everything AFTER it\n",
    "    if \"Read More\" in lyrics:\n",
    "        return lyrics.split(\"Read More\", 1)[-1].strip()\n",
    "    return lyrics.split(\"Lyrics\", 1)[-1].strip()\n",
    "\n",
    "# Apply to dataframe\n",
    "print(\"Applying 'Read More' preprocessing...\")\n",
    "df['lyrics'] = df['lyrics'].apply(lyrics_process)\n",
    "print(\"Preprocessing complete.\")\n",
    "\n",
    "# Test on a sample (optional, using the first row)\n",
    "if len(df) > 0:\n",
    "    print(\"Sample processed lyric start:\")\n",
    "    print(df['lyrics'].iloc[0][:100] + \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02bedc99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T06:24:26.412046Z",
     "start_time": "2026-01-03T06:24:26.405865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total before duplicate removal: 614\n",
      "Total after duplicate removal: 428\n",
      "Songs before cleaning: 428\n",
      "Songs after cleaning: 257\n",
      "Removed 171 songs (filters)\n",
      "\n",
      "Sample of REMOVED entries (showing reason):\n",
      "                                   title  char_count  is_tracklist language\n",
      "2                Christmas Album Cleanup        3557         False       en\n",
      "7                     IC’s Listening Log       61291          True       en\n",
      "10                INTRO (Short n’ Sweet)         210         False       en\n",
      "13                  spotify wrapped 2025         658          True       en\n",
      "17          Every Anthony Fantano Review       55798         False       en\n",
      "23          Faouziafan01's CD collection         348         False       en\n",
      "31  November 2023 Album Release Calendar       11746         False       en\n",
      "33                          Cosa Nuestra        2167         False       es\n",
      "34                         2024 Nominees        5799         False       en\n",
      "35               Albums I’ve Listened To        5191          True       en\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define thresholds\n",
    "MIN_LINES = 10\n",
    "MAX_LINES = 150\n",
    "MAX_CHARS = 5000\n",
    "MAX_SYMBOLS = 10\n",
    "\n",
    "# 1. Remove Duplicate URLs first (Aggressive removal: keep=False removes ALL duplicates)\n",
    "print(f\"Total before duplicate removal: {len(df)}\")\n",
    "df = df.drop_duplicates(subset=['url'], keep=False)\n",
    "print(f\"Total after duplicate removal: {len(df)}\")\n",
    "\n",
    "# 2. Apply Filters\n",
    "cond_lines = (df['line_count'] >= MIN_LINES) & (df['line_count'] <= MAX_LINES)\n",
    "cond_chars = (df['char_count'] <= MAX_CHARS)\n",
    "# cond_symbols = (df['symbol_count'] <= MAX_SYMBOLS) # Disabled per request\n",
    "cond_not_tracklist = (~df['is_tracklist']) # Restored (Numeric lists like \"1. Song\")\n",
    "cond_not_annotated = (~df['is_annotated'])\n",
    "cond_english = (df['language'] == 'en')\n",
    "\n",
    "# Combine filters (Removed cond_symbols)\n",
    "df_cleaned = df[cond_lines & cond_chars & cond_not_tracklist & cond_not_annotated & cond_english]\n",
    "\n",
    "print(f\"Songs before cleaning: {len(df)}\")\n",
    "print(f\"Songs after cleaning: {len(df_cleaned)}\")\n",
    "print(f\"Removed {len(df) - len(df_cleaned)} songs (filters)\")\n",
    "\n",
    "# Show removed samples\n",
    "removed = df[~(cond_lines & cond_chars & cond_not_tracklist & cond_not_annotated & cond_english)]\n",
    "if not removed.empty:\n",
    "    print(\"\\nSample of REMOVED entries (showing reason):\")\n",
    "    cols = ['title', 'char_count', 'is_tracklist', 'language']\n",
    "    print(removed[cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0113d769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T06:24:26.431105Z",
     "start_time": "2026-01-03T06:24:26.412558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned data to output/songs_with_lyrics_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_cleaned.to_csv(\"output/songs_with_lyrics_cleaned.csv\", index=False)\n",
    "print(\"Saved cleaned data to output/songs_with_lyrics_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd48e7594c34ee6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-03T06:24:26.434154Z",
     "start_time": "2026-01-03T06:24:26.431053Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JapanInternship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
